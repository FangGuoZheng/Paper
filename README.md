# Paper
# 简介：
基于XGBoost增量学习的抄袭嫌疑代码推荐系统

该项目是一个网络应用和机器学习结合的项目，主要涉及许多算法的概念。

首先，描述了教学评估系统下代码提交记录的相关特征的定义，以及算法的细节。例如，在计算代码相似度时，我们引用k-gram哈希算法，并在计算哈希值时优化算法流程，这降低了算法的时间复杂度。然而，在计算代码风格相似度时，使用编辑距离用于计算代码中空格，缩进和空白行的相似度，并使用最长公共子序列算法计算代码中注释相似度和括号相似度。最重要的是我们提出了相似集中度的概念，并给出了相似集中度基尼系数的计算公式。
然后，我们使用过滤式选择的方法，从初始样本集当中过滤掉一些相关性较弱的特征，以降低后续学习器学习任务的难度。我们采用信息增益来度量特征的重要性，若某一特征基于样本集的信息增益越大，则意味着该特征包含的有助于分类的信息就越多。于是，我们计算每一个候选特征基于样本集的信息增益，通过信息增益的大小进行排序。最后，根据指定的阈值，选取信息增益大于阈值所对应的特征。紧接着，使用Accuracy，Macro F1-Score，AUC和ROC曲线等性能指标来度量并选择模型。
最后，使用Python环境下的XGBoost工具包进行系统实现。首先，将样本数据集导入到内存当中，并将样本数据集划分为训练集和测试集。然后，将训练集转换为XGBoost自己的一种数据结构DMatrix，以加快后续计算速度。紧接着，调整好相应的模型参数，对训练集进行学习。最后，我们对每次训练产生的模型进行保存，即可保存到内存当中，也可保存为相应的二进制文件。待下次新样本数据产生时，我们可以在原来模型的基础上再次训练新的样本数据，即能在节约时间的条件下，又能产生好的新模型， 并将模型的计算结果进行排序，然后选取Top k最有可能抄袭的代码推送给老师。



Recommendation System of Plagiarism Code Based on XGBoost Incremental Learning

This project is a machine learning project, which mainly involves the concepts of many algorithms.

Firstly, we describes the definition of the relevant features of the code submission record under the teaching evaluation system, and the algorithm details. For example, when calculating the code similarity, we make use of the k-gram hash algorithm, and optimize the algorithm flow when calculating the hash value, so as to reduce the time complexity of the algorithm. When calculating the code style similarity, we take five features into account, including spaces, indents, blank lines, braces’ locations and comments in the code. We use edit distance to calculate the similarity of spaces, indents and blank lines, and use the longest common subsequence algorithm to calculate the similarity of the comments and the braces. The most important thing is that we propose the concept of similar concentration, and give the calculation formula of the similar concentration Gini coefficient.
Then, we use the filter selection method to filter out some weaker features from the initial sample set to reduce the difficulty of subsequent learner learning tasks. We use information gain to measure the importance of features. If the information gain based on a feature of the sample set is larger, it means that the feature contains more information that contributes to the classification. Thus, we calculate the information gain of each candidate feature based on the sample set, sorted by the value of the information gain. Finally, the feature whose information gain is greater than the threshold is selected according to the specified threshold. Next, we use the performance indicators such as Accuracy, Macro F1-Score, AUC and ROC curves to measure and select the model.
Finally, the XGBoost toolkit in a Python environment is used to implement system. First, the sample dataset is imported into memory and the sample dataset is divided into training and testing set. Next, convert the training set to XGBoost's own data structure, DMatrix, to speed up subsequent calculations. and adjust the corresponding model parameters and learn the training. Then, we save the model generated by each training into memory, or the corresponding binary file. When the next new sample data is generated, we can train the new sample again based on the original model, which can produce a good new model under the condition of saving time. Lastly, the top k of most likely plagiarized codes are recommended to the teachers based on the results.

------------------------------------------------------------------------------------------------------

# 特征表定义：

# PlagirismFeatures
* solution_id: int(11), Solution表的主键
* sim_soulution_id: int(11), 与该Solution相似的Id
* ASSR: float, 该学生与最大相似率同学所提交的代码风格相似率
* PR: float, 该学生的抄题率
* PCR: float, 该学生抄题的集中度
* CPMS：int(4)该学生的代码与其他同学代码的最大相似率是否超过相似度阈值；是一个过渡特征字段
* CPMSPC：int(4)该学生的代码与其他同学代码的最大相似率超过或低于阈值的百分比的类别值；是根据上一个特征转化而来
PRIMARY KEY (`solution_id`, `sim_soulution_id`)
...后续可以继续添加特征值...

# Users


# Problems
* difficulty(DL): int(4)

# Solution
* id:
* userId: 
* simUserId: 
* similarity:
* rank(RRB): int(11), 根据当前考试提交的题的分值和进行排名

 
 
 